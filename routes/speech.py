"""
Speech-to-text routes for handling audio messages.
"""

from fastapi import APIRouter, Depends, UploadFile, File, Form, HTTPException
from sqlalchemy.orm import Session
import openai
import tempfile
import os
import uuid

from database import get_db
from schemas.speech import SpeechToTextResponse
from schemas.chat import ChatRequest
from services.chat_service import chat_service

router = APIRouter(tags=["speech"])


@router.post("/speech-to-text", response_model=SpeechToTextResponse)
async def speech_to_text(
    file: UploadFile = File(...),
    client_id: str = Form(...),
    restaurant_id: str = Form(...),
    table_id: str = Form(None),
    db: Session = Depends(get_db)
):
    """
    Transcribe audio message using OpenAI Whisper and get AI response.
    
    This is a wrapper around the existing chat flow, triggered only for audio messages.
    Text messages continue to use the standard /chat endpoint.
    """
    
    print(f"\nüé§ ===== SPEECH-TO-TEXT ENDPOINT CALLED =====")
    print(f"üì® Audio message from client_id={client_id}, restaurant_id={restaurant_id}")
    print(f"üè∑Ô∏è Table ID: {table_id or 'WhatsApp (no table)'}")
    print(f"üìÅ File: {file.filename}, Content-Type: {file.content_type}")
    
    # Validate audio file
    if not file.content_type or not file.content_type.startswith('audio/'):
        raise HTTPException(status_code=400, detail="File must be an audio file")
    
    # Supported audio formats for Whisper
    supported_formats = ['.mp3', '.mp4', '.mpeg', '.mpga', '.m4a', '.wav', '.webm', '.ogg']
    file_extension = os.path.splitext(file.filename or '')[1].lower()
    
    if file_extension not in supported_formats:
        raise HTTPException(
            status_code=400, 
            detail=f"Unsupported audio format. Supported formats: {', '.join(supported_formats)}"
        )
    
    transcript = ""
    ai_response = ""
    
    try:
        # Save uploaded file temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as temp_file:
            content = await file.read()
            temp_file.write(content)
            temp_file_path = temp_file.name
        
        print(f"üíæ Saved audio file temporarily: {temp_file_path}")
        
        # Transcribe with OpenAI Whisper
        print("üéØ Starting Whisper transcription...")
        with open(temp_file_path, "rb") as audio_file:
            transcription = openai.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                response_format="text"
            )
        
        transcript = transcription.strip()
        print(f"‚úÖ Transcription successful: '{transcript}'")
        
        if not transcript:
            print("‚ö†Ô∏è Empty transcription received")
            return SpeechToTextResponse(
                transcript="",
                ai_response="I couldn't understand the audio message. Please try again or send a text message."
            )
        
        # Convert client_id to UUID for chat service
        try:
            client_uuid = uuid.UUID(client_id)
        except ValueError:
            # If client_id is not a valid UUID, create one from the string
            client_uuid = uuid.uuid5(uuid.NAMESPACE_DNS, client_id)
            print(f"üîÑ Converted client_id '{client_id}' to UUID: {client_uuid}")
        
        # Create chat request with transcribed text
        chat_request = ChatRequest(
            restaurant_id=restaurant_id,
            client_id=client_uuid,
            message=transcript,
            sender_type='client'  # Audio messages are always from clients
        )
        
        print(f"ü§ñ Calling chat service with transcribed text...")
        
        # Call existing chat service (this preserves all existing logic)
        chat_response = chat_service(chat_request, db)
        ai_response = chat_response.answer
        
        print(f"‚úÖ AI response received: '{ai_response[:100]}...' (length: {len(ai_response)})")
        
    except Exception as e:
        print(f"‚ùå Error in speech-to-text processing: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Speech processing failed: {str(e)}")
    
    finally:
        # Clean up temporary file
        try:
            if 'temp_file_path' in locals():
                os.unlink(temp_file_path)
                print(f"üóëÔ∏è Cleaned up temporary file: {temp_file_path}")
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to clean up temporary file: {e}")
    
    print(f"===== END SPEECH-TO-TEXT ENDPOINT =====\n")
    
    return SpeechToTextResponse(
        transcript=transcript,
        ai_response=ai_response
    )

